{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Regression Used Cars Dataset\n","\n","https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data \n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Dependency**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:31:48.975295Z","iopub.status.busy":"2024-04-01T09:31:48.974873Z","iopub.status.idle":"2024-04-01T09:31:50.163809Z","shell.execute_reply":"2024-04-01T09:31:50.162429Z","shell.execute_reply.started":"2024-04-01T09:31:48.975261Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from itertools import combinations  # For creating combinations of elements\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n","from sklearn.linear_model import LinearRegression\n","from sklearn.cluster import KMeans\n","from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n","from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n","from sklearn.compose import make_column_transformer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import cross_val_score\n","from scipy.stats import randint as sp_randint\n","from scipy.stats import uniform"]},{"cell_type":"markdown","metadata":{},"source":["#### **Utility Function**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:31:50.167170Z","iopub.status.busy":"2024-04-01T09:31:50.166559Z","iopub.status.idle":"2024-04-01T09:31:50.181726Z","shell.execute_reply":"2024-04-01T09:31:50.180338Z","shell.execute_reply.started":"2024-04-01T09:31:50.167130Z"},"trusted":true},"outputs":[],"source":["def reduce_mem_usage(df, verbose=0):\n","    \"\"\"\n","    Iterate through all numeric columns of a dataframe and modify the data type\n","    to reduce memory usage.\n","    \"\"\"\n","    # Calculate the initial memory usage of the DataFrame\n","    start_mem = df.memory_usage().sum() / 1024**2\n","\n","    # ðŸ”„ Iterate through each column in the DataFrame\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        # Check if the column's data type is not 'object' (i.e., numeric)\n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            # Check if the column's data type is an integer\n","            if str(col_type)[:3] == \"int\":\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                # Check if the column's data type is a float\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float32)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float32)\n","    # â„¹ï¸ Provide memory optimization information if 'verbose' is True\n","    if verbose:\n","        print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n","        end_mem = df.memory_usage().sum() / 1024**2\n","        print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n","        decrease = 100 * (start_mem - end_mem) / start_mem\n","        print(f\"Decreased by {decrease:.2f}%\")\n","\n","    # Return the DataFrame with optimized memory usage\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["#### **Load Data**\n","\n","load csv inside data folder"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:31:50.183921Z","iopub.status.busy":"2024-04-01T09:31:50.183477Z","iopub.status.idle":"2024-04-01T09:32:21.083357Z","shell.execute_reply":"2024-04-01T09:32:21.082047Z","shell.execute_reply.started":"2024-04-01T09:31:50.183861Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory usage of dataframe is 84.68 MB\n","Memory usage after optimization is: 76.54 MB\n","Decreased by 9.62%\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url</th>\n","      <th>region</th>\n","      <th>region_url</th>\n","      <th>price</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>model</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>...</th>\n","      <th>size</th>\n","      <th>type</th>\n","      <th>paint_color</th>\n","      <th>image_url</th>\n","      <th>description</th>\n","      <th>county</th>\n","      <th>state</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>posting_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7222695916</td>\n","      <td>https://prescott.craigslist.org/cto/d/prescott...</td>\n","      <td>prescott</td>\n","      <td>https://prescott.craigslist.org</td>\n","      <td>6000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>az</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7218891961</td>\n","      <td>https://fayar.craigslist.org/ctd/d/bentonville...</td>\n","      <td>fayetteville</td>\n","      <td>https://fayar.craigslist.org</td>\n","      <td>11900</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ar</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7221797935</td>\n","      <td>https://keys.craigslist.org/cto/d/summerland-k...</td>\n","      <td>florida keys</td>\n","      <td>https://keys.craigslist.org</td>\n","      <td>21000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>fl</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7222270760</td>\n","      <td>https://worcester.craigslist.org/cto/d/west-br...</td>\n","      <td>worcester / central MA</td>\n","      <td>https://worcester.craigslist.org</td>\n","      <td>1500</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ma</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4 rows Ã— 26 columns</p>\n","</div>"],"text/plain":["           id                                                url  \\\n","0  7222695916  https://prescott.craigslist.org/cto/d/prescott...   \n","1  7218891961  https://fayar.craigslist.org/ctd/d/bentonville...   \n","2  7221797935  https://keys.craigslist.org/cto/d/summerland-k...   \n","3  7222270760  https://worcester.craigslist.org/cto/d/west-br...   \n","\n","                   region                        region_url  price  year  \\\n","0                prescott   https://prescott.craigslist.org   6000   NaN   \n","1            fayetteville      https://fayar.craigslist.org  11900   NaN   \n","2            florida keys       https://keys.craigslist.org  21000   NaN   \n","3  worcester / central MA  https://worcester.craigslist.org   1500   NaN   \n","\n","  manufacturer model condition cylinders  ... size  type paint_color  \\\n","0          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n","1          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n","2          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n","3          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n","\n","  image_url description county state lat long posting_date  \n","0       NaN         NaN    NaN    az NaN  NaN          NaN  \n","1       NaN         NaN    NaN    ar NaN  NaN          NaN  \n","2       NaN         NaN    NaN    fl NaN  NaN          NaN  \n","3       NaN         NaN    NaN    ma NaN  NaN          NaN  \n","\n","[4 rows x 26 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"kaggle/input/vehicles/vehicles.csv\")\n","df=reduce_mem_usage(df,verbose=True)\n","df.shape\n","df[0:4]"]},{"cell_type":"markdown","metadata":{},"source":["#### **Split dataset** "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:32:21.085625Z","iopub.status.busy":"2024-04-01T09:32:21.085173Z","iopub.status.idle":"2024-04-01T09:32:22.268583Z","shell.execute_reply":"2024-04-01T09:32:22.267239Z","shell.execute_reply.started":"2024-04-01T09:32:21.085577Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(341504, 26) (85376, 26)\n"]}],"source":["df_train, df_test = train_test_split(df, test_size=0.2)\n","print(df_train.shape, df_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["#### **Data Function**\n","\n","data preperation\n","\n","feature engineering"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:32:22.274331Z","iopub.status.busy":"2024-04-01T09:32:22.273872Z","iopub.status.idle":"2024-04-01T09:32:22.291375Z","shell.execute_reply":"2024-04-01T09:32:22.289704Z","shell.execute_reply.started":"2024-04-01T09:32:22.274293Z"},"trusted":true},"outputs":[],"source":["# implement the function\n","def data_preparation(df:pd.DataFrame)->pd.DataFrame:\n","    \"\"\"\"\n","    make data valid\n","    \"\"\"\n","    #Create df1, get the average value of deleting NAN and outliers, then assign it to the NAN in df, \n","    #and then delete the outliers in df to get the latest data set\n","    df1 = df.copy()\n","    odometer_data = df1['odometer']\n","    odometer_data_cleaned = odometer_data.dropna()\n","    kmeans = KMeans(n_clusters=4)\n","    kmeans.fit(odometer_data_cleaned.values.reshape(-1, 1))\n","\n","    outliers = odometer_data_cleaned[kmeans.labels_ == 1]\n","    df1 = df1[~df1['odometer'].isin(outliers)]\n","    average_value = df1['odometer'].mean()\n","    df['odometer'] = df['odometer'].fillna(average_value)\n","    \n","    #Use Kmeans to calculate outliers and delete them together with data with a price less than 1,000\n","    #($1,000 is about ï¿¥7,500. Even the price of a second-hand car is too low, so it is also regarded as an outlier and deleted)\n","    price_data = df['price']\n","    kmeans = KMeans(n_clusters=2)\n","    kmeans.fit(price_data.values.reshape(-1, 1))\n","    outliers = price_data[kmeans.labels_ == 1]\n","\n","    df = df[~((price_data.isin(outliers)) | (price_data < 1000))]\n","    \n","    #use linear regression to prediect values for null in year col.\n","    features = [\"price\",'odometer']\n","    df_complete = df.dropna(subset=[\"year\"] + features)\n","    X_train = df_complete[features]\n","    y_train = df_complete[\"year\"]\n","    regression_model_year = LinearRegression()\n","    regression_model_year.fit(X_train, y_train)\n","    X_missing = df[df[\"year\"].isnull()][features]\n","    predicted_year = regression_model_year.predict(X_missing)\n","\n","    df.loc[df[\"year\"].isnull(), \"year\"] = predicted_year.round().astype(int)\n","    \n","    #Fill null values using the modes of \"manufacturer\", \"cylinders\", 'fuel',\"title_status\", \"transmission\",\"drive\", \"type\", \"paint_color\", \"lat\", \"long\"\n","    columns_to_fillna = ['manufacturer', 'cylinders', 'fuel', 'title_status', 'transmission',\n","                     'drive', 'type', 'paint_color', 'lat', 'long','posting_date']\n","    modes = df[columns_to_fillna].mode().iloc[0]\n","    df.loc[:, columns_to_fillna] = df.loc[:, columns_to_fillna].fillna(value=modes)\n","    \n","    #for \"condition\" col: Fill NAN with randomly selected data from that column to manipulate the more possible results.\n","    condition_options = df[\"condition\"].unique()\n","    df.loc[df[\"condition\"].isnull(), \"condition\"] = np.random.choice(condition_options)\n","\n","    # turn nominal data into number\n","    y = df['price']\n","    x =df.drop(columns=['price'])\n","\n","\n","    return x,y\n","\n","def feature_engineering(df:pd.DataFrame)->pd.DataFrame:\n","    \"\"\"\"\n","    select useful feature\n","    \"\"\"\n","    #vehicle_age=posting_year - year, get the usage time of this vehicle\n","    df[\"posting_date\"] = pd.to_datetime(df[\"posting_date\"], utc=True)\n","    df[\"posting_year\"] = df[\"posting_date\"].dt.year\n","    df[\"vehicle_age\"] = df[\"posting_year\"] - df[\"year\"]\n","    \n","    #Remove meaningless columns\n","    df.drop(['id','url','region','region_url','model','title_status',\n","         'image_url','VIN','size','county','description',\n","         'state','lat','long','posting_date','posting_year'], \n","        axis=1, inplace=True)\n","    \n","    return df\n","\n","def data_preprocessing(df:pd.DataFrame)->pd.DataFrame:\n","    x , y =data_preparation(df)\n","    x=feature_engineering(x)\n","    return x,y\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:32:22.293475Z","iopub.status.busy":"2024-04-01T09:32:22.292938Z","iopub.status.idle":"2024-04-01T09:32:30.166738Z","shell.execute_reply":"2024-04-01T09:32:30.165570Z","shell.execute_reply.started":"2024-04-01T09:32:22.293429Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(304375, 11) (304375,)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>type</th>\n","      <th>paint_color</th>\n","      <th>vehicle_age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>173190</th>\n","      <td>1968.0</td>\n","      <td>ford</td>\n","      <td>fair</td>\n","      <td>8 cylinders</td>\n","      <td>gas</td>\n","      <td>9000.0</td>\n","      <td>automatic</td>\n","      <td>rwd</td>\n","      <td>coupe</td>\n","      <td>custom</td>\n","      <td>53.0</td>\n","    </tr>\n","    <tr>\n","      <th>217477</th>\n","      <td>2012.0</td>\n","      <td>chevrolet</td>\n","      <td>good</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>120795.0</td>\n","      <td>automatic</td>\n","      <td>4wd</td>\n","      <td>SUV</td>\n","      <td>silver</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>277451</th>\n","      <td>2008.0</td>\n","      <td>nissan</td>\n","      <td>excellent</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>145000.0</td>\n","      <td>automatic</td>\n","      <td>4wd</td>\n","      <td>SUV</td>\n","      <td>brown</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>56055</th>\n","      <td>1951.0</td>\n","      <td>gmc</td>\n","      <td>fair</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>34000.0</td>\n","      <td>manual</td>\n","      <td>rwd</td>\n","      <td>pickup</td>\n","      <td>white</td>\n","      <td>70.0</td>\n","    </tr>\n","    <tr>\n","      <th>96833</th>\n","      <td>2015.0</td>\n","      <td>cadillac</td>\n","      <td>like new</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>50809.0</td>\n","      <td>automatic</td>\n","      <td>4wd</td>\n","      <td>other</td>\n","      <td>silver</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>30997</th>\n","      <td>2016.0</td>\n","      <td>chevrolet</td>\n","      <td>like new</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>56000.0</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>SUV</td>\n","      <td>white</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>121764</th>\n","      <td>2009.0</td>\n","      <td>honda</td>\n","      <td>excellent</td>\n","      <td>3 cylinders</td>\n","      <td>gas</td>\n","      <td>1.0</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>sedan</td>\n","      <td>silver</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>267037</th>\n","      <td>2015.0</td>\n","      <td>chevrolet</td>\n","      <td>good</td>\n","      <td>8 cylinders</td>\n","      <td>other</td>\n","      <td>51677.0</td>\n","      <td>other</td>\n","      <td>4wd</td>\n","      <td>other</td>\n","      <td>black</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>113401</th>\n","      <td>2011.0</td>\n","      <td>hyundai</td>\n","      <td>good</td>\n","      <td>4 cylinders</td>\n","      <td>gas</td>\n","      <td>137000.0</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>hatchback</td>\n","      <td>black</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>20898</th>\n","      <td>2015.0</td>\n","      <td>ford</td>\n","      <td>like new</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>78379.0</td>\n","      <td>automatic</td>\n","      <td>4wd</td>\n","      <td>sedan</td>\n","      <td>white</td>\n","      <td>6.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          year manufacturer  condition    cylinders   fuel  odometer  \\\n","173190  1968.0         ford       fair  8 cylinders    gas    9000.0   \n","217477  2012.0    chevrolet       good  6 cylinders    gas  120795.0   \n","277451  2008.0       nissan  excellent  6 cylinders    gas  145000.0   \n","56055   1951.0          gmc       fair  6 cylinders    gas   34000.0   \n","96833   2015.0     cadillac   like new  6 cylinders    gas   50809.0   \n","30997   2016.0    chevrolet   like new  6 cylinders    gas   56000.0   \n","121764  2009.0        honda  excellent  3 cylinders    gas       1.0   \n","267037  2015.0    chevrolet       good  8 cylinders  other   51677.0   \n","113401  2011.0      hyundai       good  4 cylinders    gas  137000.0   \n","20898   2015.0         ford   like new  6 cylinders    gas   78379.0   \n","\n","       transmission drive       type paint_color  vehicle_age  \n","173190    automatic   rwd      coupe      custom         53.0  \n","217477    automatic   4wd        SUV      silver          9.0  \n","277451    automatic   4wd        SUV       brown         13.0  \n","56055        manual   rwd     pickup       white         70.0  \n","96833     automatic   4wd      other      silver          6.0  \n","30997     automatic   fwd        SUV       white          5.0  \n","121764    automatic   fwd      sedan      silver         12.0  \n","267037        other   4wd      other       black          6.0  \n","113401    automatic   fwd  hatchback       black         10.0  \n","20898     automatic   4wd      sedan       white          6.0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_train_x,df_train_y = data_preprocessing(df_train)\n","df_test_x, df_test_y = data_preprocessing(df_test)\n","\n","print(df_train_x.shape, df_train_y.shape)\n","df_train_x[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### **Training and Evaluation**"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"ename":"ValueError","evalue":"could not convert string to float: 'ford'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m paramgrid\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#cross validation \u001b[39;00m\n\u001b[0;32m      7\u001b[0m modelCV\u001b[38;5;241m=\u001b[39m GridSearchCV(model,paramgrid,n_jobs\u001b[38;5;241m=\u001b[39mnumJobs,cv\u001b[38;5;241m=\u001b[39mcv)\n","File \u001b[1;32md:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:578\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    574\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    576\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 578\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n","File \u001b[1;32md:\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n","File \u001b[1;32md:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n","File \u001b[1;32md:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n","File \u001b[1;32md:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n","File \u001b[1;32md:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:2084\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2083\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 2084\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2086\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2087\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2088\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2089\u001b[0m     ):\n\u001b[0;32m   2090\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2091\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2092\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2093\u001b[0m         ):\n","\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ford'"]}],"source":["numJobs=3\n","cv=5\n","paramgrid={}\n","\n","model = LinearRegression().fit(df_train_x, df_train_y)\n","#cross validation \n","modelCV= GridSearchCV(model,paramgrid,n_jobs=numJobs,cv=cv)\n","\n","#predict\n","y_pred = modelCV.predict(df_test_x)\n","\n","#evaluation\n","\n","# RMSE\n","rmse = np.sqrt(mean_squared_error(df_test_y, y_pred))\n","print(f\"Root Mean Squared Error: {rmse}\")\n","\n","# MAE\n","mae = mean_absolute_error(df_test_y, y_pred)\n","print(f\"Mean Absolute Error: {mae}\")\n","\n","# R2\n","r2 = r2_score(df_test_y, y_pred)\n","print(f\"R-squared: {r2}\")\n","\n","#Residual Analysis: \n","residuals = df_test_y - y_pred\n","\n","plt.scatter(y_pred, residuals)\n","plt.axhline(y=0, color='r', linestyle='--')\n","plt.xlabel('Predicted Values')\n","plt.ylabel('Residuals')\n","plt.title('Residual Plot')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### **Training and Evaluation by Hessia**"]},{"cell_type":"markdown","metadata":{},"source":["### Label and Normalization\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["preprocessor = make_column_transformer(\n","    (OneHotEncoder(), [\"manufacturer\",'condition', 'cylinders', 'fuel', 'transmission', 'drive', 'type', 'paint_color' ]),\n","    (StandardScaler(), [\"year\",\"odometer\",\"vehicle_age\"]),\n","    remainder=\"passthrough\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Regressor\n"]},{"cell_type":"markdown","metadata":{},"source":["#### RandomSearch, GridSearch and Test Function "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def random_search(_model,_preprocessor,_param_dist):\n","    pipeline = make_pipeline(_preprocessor, _model)\n","    random = RandomizedSearchCV(pipeline, param_distributions=_param_dist, n_iter=100, cv=5, n_jobs=16)\n","    random.fit(df_train_x, df_train_y)\n","    # Print the best hyperparameters and the corresponding score\n","    print(\"Best parameters: {}\".format(random.best_params_))\n","    print(\"Best cross-validation score: {:.2f}\".format(random.best_score_))\n","    return random\n","\n","\n","def grid_search(_model,_preprocessor,_param_grid):\n","    # Define the Gradient Boosting regression model\n","    # Define the pipeline to preprocess the features and fit the model\n","    pipeline = make_pipeline(_preprocessor, _model)\n","    grid = GridSearchCV(pipeline, param_grid=_param_grid, cv=5, n_jobs=16)\n","    grid.fit(df_train_x, df_train_y)\n","    # Print the best hyperparameters and the corresponding score\n","    print(\"Best parameters: {}\".format(grid.best_params_))\n","    print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n","    return grid\n","    \n","def test_score(_model,_preprocessor):\n","    best_pipeline = make_pipeline(_preprocessor, _model)\n","    best_pipeline.fit(df_train_x, df_train_y)\n","    df_test_pred = best_pipeline.predict(df_test_x)\n","    rmse = np.sqrt(mean_squared_error(df_test_y, df_test_pred))\n","    mae = mean_absolute_error(df_test_y, df_test_pred)\n","    r2 = r2_score(df_test_y, df_test_pred)\n","    print(\"R2 score: {}\".format(r2))\n","    print(\"RMSE: {}\".format(rmse))\n","    print(\"MAE: {}\".format(mae))\n","def test_score_param(_grid):\n","    df_test_pred = _grid.best_estimator_.predict(df_test_x)\n","    rmse = np.sqrt(mean_squared_error(df_test_y, df_test_pred))\n","    mae = mean_absolute_error(df_test_y, df_test_pred)\n","    r2 = r2_score(df_test_y, df_test_pred)\n","    print(\"R2 score: {}\".format(r2))\n","    print(\"RMSE: {}\".format(rmse))\n","    print(\"MAE: {}\".format(mae))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### run RandomSearch"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["param_dist = {\n","        \"gradientboostingregressor__n_estimators\": sp_randint(50, 200),\n","        \"gradientboostingregressor__max_depth\": sp_randint(5, 10),\n","        \"gradientboostingregressor__learning_rate\": uniform(0.0, 1.0),\n","        \"gradientboostingregressor__subsample\": uniform(0.0, 1.0),\n","        \"gradientboostingregressor__loss\": ['squared_error', 'quantile', 'huber', 'absolute_error'],\n","        \"gradientboostingregressor__min_samples_split\": sp_randint(2, 10),\n","        \"gradientboostingregressor__min_samples_leaf\": sp_randint(1, 10),\n","        \"gradientboostingregressor__max_features\": ['sqrt', 'log2', None],\n","        \"gradientboostingregressor__min_impurity_decrease\": uniform(0.0, 0.1)\n","    }\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["param_grid = {\n","        \"gradientboostingregressor__n_estimators\": [120,128,135,145],\n","        \"gradientboostingregressor__max_depth\": [6, 7, 8],\n","        \"gradientboostingregressor__learning_rate\": [0.55,0.6366443216222826,0.7,0.75],\n","        \"gradientboostingregressor__subsample\": [0.3, 0.39654278232127016, 0.5],\n","        \"gradientboostingregressor__loss\": ['huber'],\n","        \"gradientboostingregressor__min_samples_split\": [1,2,3],\n","        \"gradientboostingregressor__min_samples_leaf\": [3,4,5],\n","        \"gradientboostingregressor__max_features\": ['sqrt', 'log2', None],\n","        \"gradientboostingregressor__min_impurity_decrease\": [0.8,0.09041586944937485, 0.1]\n","    }\n"]},{"cell_type":"markdown","metadata":{},"source":["## GradientBoostingRegressor"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters: {}\n","Best cross-validation score: -0.31\n","R2 score: 0.16094345662558918\n","RMSE: 3303833.9760006675\n","MAE: 46915.341121454476\n"]}],"source":["best_model = GradientBoostingRegressor(\n","        n_estimators=100,\n","        max_depth=7,\n","        learning_rate=1,\n","        subsample=0.8,\n","        loss='huber',\n","        random_state=42\n","    )\n","best_model_2=GradientBoostingRegressor(\n","        n_estimators=128,\n","        max_depth=7,\n","        learning_rate=0.6366443216222826,\n","        subsample=0.39654278232127016,\n","        loss='huber',\n","        min_samples_leaf=4,\n","        min_impurity_decrease=0.09041586944937485,\n","        min_samples_split=2\n",")\n","param_grid_G={}\n","grid_G=grid_search(GradientBoostingRegressor(),preprocessor,param_grid_G)\n","test_score_param(grid_G)"]},{"cell_type":"markdown","metadata":{},"source":["## XGBRegressor"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score: 0.3429775335073124\n","RMSE: 4681957.902403922\n","MAE: 61732.29532345271\n"]}],"source":["from xgboost import XGBRegressor\n","param_grid_X={}\n","grid_X=grid_search(XGBRegressor(),preprocessor,param_grid_X)\n","test_score_param(grid_X)"]},{"cell_type":"markdown","metadata":{},"source":["## LinearRegression"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score: -0.0002456337743594883\n","RMSE: 5762778.706001976\n","MAE: 105652.0382011966\n"]}],"source":["\n","param_grid_L={}\n","grid_L=grid_search(LinearRegression(),preprocessor,param_grid_L)\n","test_score_param(grid_L)"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest Regression"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["param_grid_R={}\n","grid_R=grid_search(LinearRegression(),preprocessor,param_grid_R)\n","test_score_param(grid_R)"]},{"cell_type":"markdown","metadata":{},"source":["### DecisionTreeRegressor\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score: -0.7986807042236448\n","RMSE: 7727795.990752676\n","MAE: 58473.15672608925\n"]}],"source":["from sklearn.tree import DecisionTreeRegressor\n","\n","param_grid_D={}\n","grid_D=grid_search(DecisionTreeRegressor(),preprocessor,param_grid_D)\n","test_score_param(grid_D)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4704710,"sourceId":7991539,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
