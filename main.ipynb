{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Used Cars Dataset\n",
    "\n",
    "https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dependency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install lightgbm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from itertools import combinations  # For creating combinations of elements\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "import lightgbm as lgb \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Utility Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    \"\"\"\n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    # Calculate the initial memory usage of the DataFrame\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    # 🔄 Iterate through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        # Check if the column's data type is not 'object' (i.e., numeric)\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            # Check if the column's data type is an integer\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            elif str(col_type)[:5] == \"float\":\n",
    "                # Check if the column's data type is a float\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    # ℹ️ Provide memory optimization information if 'verbose' is True\n",
    "    if verbose:\n",
    "        print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        print(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    # Return the DataFrame with optimized memory usage\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Data**\n",
    "\n",
    "load csv inside data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 87.53 MB\n",
      "Memory usage after optimization is: 87.53 MB\n",
      "Decreased by 0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>...</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>posting_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7222695916</td>\n",
       "      <td>https://prescott.craigslist.org/cto/d/prescott...</td>\n",
       "      <td>prescott</td>\n",
       "      <td>https://prescott.craigslist.org</td>\n",
       "      <td>6000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>az</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7218891961</td>\n",
       "      <td>https://fayar.craigslist.org/ctd/d/bentonville...</td>\n",
       "      <td>fayetteville</td>\n",
       "      <td>https://fayar.craigslist.org</td>\n",
       "      <td>11900</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ar</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7221797935</td>\n",
       "      <td>https://keys.craigslist.org/cto/d/summerland-k...</td>\n",
       "      <td>florida keys</td>\n",
       "      <td>https://keys.craigslist.org</td>\n",
       "      <td>21000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>fl</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7222270760</td>\n",
       "      <td>https://worcester.craigslist.org/cto/d/west-br...</td>\n",
       "      <td>worcester / central MA</td>\n",
       "      <td>https://worcester.craigslist.org</td>\n",
       "      <td>1500</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ma</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                                url  \\\n",
       "0  7222695916  https://prescott.craigslist.org/cto/d/prescott...   \n",
       "1  7218891961  https://fayar.craigslist.org/ctd/d/bentonville...   \n",
       "2  7221797935  https://keys.craigslist.org/cto/d/summerland-k...   \n",
       "3  7222270760  https://worcester.craigslist.org/cto/d/west-br...   \n",
       "\n",
       "                   region                        region_url  price  year  \\\n",
       "0                prescott   https://prescott.craigslist.org   6000  <NA>   \n",
       "1            fayetteville      https://fayar.craigslist.org  11900  <NA>   \n",
       "2            florida keys       https://keys.craigslist.org  21000  <NA>   \n",
       "3  worcester / central MA  https://worcester.craigslist.org   1500  <NA>   \n",
       "\n",
       "  manufacturer model condition cylinders  ...  size  type paint_color  \\\n",
       "0         <NA>  <NA>      <NA>      <NA>  ...  <NA>  <NA>        <NA>   \n",
       "1         <NA>  <NA>      <NA>      <NA>  ...  <NA>  <NA>        <NA>   \n",
       "2         <NA>  <NA>      <NA>      <NA>  ...  <NA>  <NA>        <NA>   \n",
       "3         <NA>  <NA>      <NA>      <NA>  ...  <NA>  <NA>        <NA>   \n",
       "\n",
       "  image_url description county state   lat  long posting_date  \n",
       "0      <NA>        <NA>   <NA>    az  <NA>  <NA>         <NA>  \n",
       "1      <NA>        <NA>   <NA>    ar  <NA>  <NA>         <NA>  \n",
       "2      <NA>        <NA>   <NA>    fl  <NA>  <NA>         <NA>  \n",
       "3      <NA>        <NA>   <NA>    ma  <NA>  <NA>         <NA>  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/vehicles.csv\")\n",
    "df=df.convert_dtypes()\n",
    "df=reduce_mem_usage(df,verbose=True)\n",
    "df.shape\n",
    "df[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 26 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            426880 non-null  Int64  \n",
      " 1   url           426880 non-null  string \n",
      " 2   region        426880 non-null  string \n",
      " 3   region_url    426880 non-null  string \n",
      " 4   price         426880 non-null  Int64  \n",
      " 5   year          425675 non-null  Int64  \n",
      " 6   manufacturer  409234 non-null  string \n",
      " 7   model         421603 non-null  string \n",
      " 8   condition     252776 non-null  string \n",
      " 9   cylinders     249202 non-null  string \n",
      " 10  fuel          423867 non-null  string \n",
      " 11  odometer      422480 non-null  Int64  \n",
      " 12  title_status  418638 non-null  string \n",
      " 13  transmission  424324 non-null  string \n",
      " 14  VIN           265838 non-null  string \n",
      " 15  drive         296313 non-null  string \n",
      " 16  size          120519 non-null  string \n",
      " 17  type          334022 non-null  string \n",
      " 18  paint_color   296677 non-null  string \n",
      " 19  image_url     426812 non-null  string \n",
      " 20  description   426810 non-null  string \n",
      " 21  county        0 non-null       Int64  \n",
      " 22  state         426880 non-null  string \n",
      " 23  lat           420331 non-null  Float64\n",
      " 24  long          420331 non-null  Float64\n",
      " 25  posting_date  426812 non-null  string \n",
      "dtypes: Float64(2), Int64(5), string(19)\n",
      "memory usage: 87.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                  'f-150 xlt',  'ranger supercrew xl pickup',\n",
       " 'f150 super cab xl pickup 4d',      'f150 supercrew cab xlt',\n",
       "   'ranger supercab xl pickup',             'f250 super duty',\n",
       "  'f150 regular cab xl pickup',          'mustang gt premium',\n",
       "                        'f450',        'expedition xlt sport',\n",
       " ...\n",
       "     'e450 super duty cutaway',   'e-series chassis e-350 sd',\n",
       "              'f15o fx4 sport',              'f-150 heritage',\n",
       "         'ranger pickup truck',                  'ranger rmt',\n",
       "        'f250 crew cab diesel',             'taurus wagon lx',\n",
       "                   'f150, xlt',              'f150, platinum']\n",
       "Length: 3875, dtype: string"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['manufacturer']==\"ford\")]['model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Split dataset** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341504, 26) (85376, 26)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Function**\n",
    "\n",
    "data preperation\n",
    "\n",
    "feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def keep_first_word(s):\n",
    "    return s.split()[0]\n",
    "\n",
    "# Apply the function to the column\n",
    "df['column1'] = df['column1'].apply(keep_first_word)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def data_preparation(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\"\n",
    "    make data valid\n",
    "    \"\"\"\n",
    "    def keep_first_word(s):\n",
    "        if pd.notnull(s):  # Use pd.notnull instead of not pd.isnull\n",
    "            s = str(s).lower()\n",
    "            s=s.split()[0]\n",
    "            s = re.sub('[^a-zA-Z0-9]', '', s)\n",
    "            if(len(s)<3):\n",
    "                return np.nan\n",
    "            else:\n",
    "                return s\n",
    "        else:\n",
    "            return np.nan  # Return np.nan for null values\n",
    "\n",
    "    # process model col\n",
    "    df['model'] = df['model'].apply(keep_first_word)\n",
    "    df['model'] = df['model'].fillna(\"others\")\n",
    "    md = df['model'].value_counts()\n",
    "    df['model'] = df['model'].apply(lambda s: str(s) if str(s) in md[:50] else \"others\")\n",
    "\n",
    "    mf = df['manufacturer'].value_counts()\n",
    "    df['manufacturer'] = df['manufacturer'].apply(lambda s: str(s) if str(s) in mf[:20] else \"others\")\n",
    "\n",
    "    \n",
    "    # fill data from real world !!!!!!\n",
    "    temp = df.loc[(df['manufacturer']==\"ford\") & (df['model']==\"f150\")]\n",
    "    df.loc[temp.index, \"cylinders\"]=df.loc[(df['manufacturer']==\"ford\") & (df['model']==\"f150\"), \"cylinders\"].fillna(\"6 cylinders\")\n",
    "    df['cylinders'] = df['cylinders']\n",
    "\n",
    "    # clean the odometer data by computing averge between 0.05 and 0.95\n",
    "    o1 = df['odometer'].quantile(0.95)\n",
    "    o2 = df['odometer'].quantile(0.05)\n",
    "    odometer_avg= df[(df['odometer']<o1) & (df['odometer']>o2)]['odometer'].mean()\n",
    "    df['odometer'] = df['odometer'].fillna(int(odometer_avg))\n",
    "    \n",
    "\n",
    "    df = df.dropna(subset=['year'])\n",
    "\n",
    "\n",
    "    # turn nominal data into number\n",
    "    y = df['price']\n",
    "    x =df.drop(columns=['price'])\n",
    "    x=x.convert_dtypes()\n",
    "\n",
    "    return x,y\n",
    "\n",
    "def feature_engineering(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\"\n",
    "    select useful feature\n",
    "    \"\"\"\n",
    "    #vehicle_age=posting_year - year, get the usage time of this vehicle\n",
    "    df[\"posting_date\"] = pd.to_datetime(df[\"posting_date\"], utc=True)\n",
    "    df[\"posting_year\"] = df[\"posting_date\"].dt.year\n",
    "    df[\"vehicle_age\"] = df[\"posting_year\"] - df[\"year\"]\n",
    "    \n",
    "    #Remove meaningless columns\n",
    "    df.drop(['id','url','region','region_url','title_status',\n",
    "         'image_url','VIN','size','county','description',\n",
    "         'state','lat','long','posting_date','posting_year'], \n",
    "        axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def data_preprocessing(df:pd.DataFrame)->pd.DataFrame:\n",
    "    x , y =data_preparation(df)\n",
    "    x=feature_engineering(x)\n",
    "    return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                 0\n",
      "manufacturer         0\n",
      "model                0\n",
      "condition       138420\n",
      "cylinders       137169\n",
      "fuel              2212\n",
      "odometer             0\n",
      "transmission      1955\n",
      "drive           104211\n",
      "type             74324\n",
      "paint_color     104064\n",
      "vehicle_age          0\n",
      "dtype: int64\n",
      "<StringArray>\n",
      "[         <NA>,      'pickup',       'truck',       'other',       'coupe',\n",
      "         'SUV',   'hatchback',    'mini-van',       'sedan',     'offroad',\n",
      "         'bus',         'van', 'convertible',       'wagon']\n",
      "Length: 14, dtype: string\n",
      "(340528, 12) (340528,)\n"
     ]
    }
   ],
   "source": [
    "df_train_x,df_train_y = data_preprocessing(df_train)\n",
    "df_test_x, df_test_y = data_preprocessing(df_test)\n",
    "\n",
    "print(df_train_x.isna().sum())\n",
    "print(df['type'].unique())\n",
    "print(df_train_x.shape, df_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 340528 entries, 29165 to 233708\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   year          340528 non-null  Int64 \n",
      " 1   manufacturer  340528 non-null  string\n",
      " 2   model         340528 non-null  string\n",
      " 3   condition     202108 non-null  string\n",
      " 4   cylinders     203359 non-null  string\n",
      " 5   fuel          338316 non-null  string\n",
      " 6   odometer      340528 non-null  Int64 \n",
      " 7   transmission  338573 non-null  string\n",
      " 8   drive         236317 non-null  string\n",
      " 9   type          266204 non-null  string\n",
      " 10  paint_color   236464 non-null  string\n",
      " 11  vehicle_age   340528 non-null  Int64 \n",
      "dtypes: Int64(3), string(9)\n",
      "memory usage: 34.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681056 entries, 0 to 681055\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   year          681056 non-null  Int64 \n",
      " 1   manufacturer  681056 non-null  string\n",
      " 2   model         681056 non-null  string\n",
      " 3   condition     404216 non-null  string\n",
      " 4   cylinders     406718 non-null  string\n",
      " 5   fuel          676632 non-null  string\n",
      " 6   odometer      681056 non-null  Int64 \n",
      " 7   transmission  677146 non-null  string\n",
      " 8   drive         472634 non-null  string\n",
      " 9   type          532408 non-null  string\n",
      " 10  paint_color   472928 non-null  string\n",
      " 11  vehicle_age   681056 non-null  Int64 \n",
      "dtypes: Int64(3), string(9)\n",
      "memory usage: 64.3 MB\n"
     ]
    }
   ],
   "source": [
    "temppd = pd.concat([df_train_x, df_train_x],ignore_index=True)\n",
    "temppd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'transmission', 'drive', 'type', 'paint_color']\n",
      "21\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'volkswagen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategorical_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# get the encoder \u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m encoders \u001b[38;5;241m=\u001b[39m getEncoder(categorical_cols,temppd)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#convert\u001b[39;00m\n\u001b[0;32m     32\u001b[0m df_train_x \u001b[38;5;241m=\u001b[39m encode(df_train_x,encoders,categorical_cols\u001b[38;5;241m=\u001b[39mcategorical_cols)\n",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m, in \u001b[0;36mgetEncoder\u001b[1;34m(categorical_cols, df)\u001b[0m\n\u001b[0;32m      6\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_train_x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanufacturer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(clusters)\n\u001b[1;32m----> 8\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mclusters, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(df[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      9\u001b[0m     encoders\u001b[38;5;241m.\u001b[39mappend(kmeans)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoders\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1471\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \n\u001b[0;32m   1447\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1471\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1472\u001b[0m         X,\n\u001b[0;32m   1473\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1474\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[0;32m   1475\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1476\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_x,\n\u001b[0;32m   1477\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1478\u001b[0m     )\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m   1482\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'volkswagen'"
     ]
    }
   ],
   "source": [
    "#construct label encoder\n",
    "\n",
    "def getEncoder(categorical_cols,df1,df2):\n",
    "    for col in categorical_cols:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        df1[col]=le.fit_transform(df1[col])\n",
    "        df2[col] = le.transform(df2[col])\n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "\n",
    "cols = df_test_x.columns.values.tolist()\n",
    "categorical_cols = []\n",
    "for col in cols:\n",
    "    if df_test_x[col].dtype == \"string\":\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "print(f\"{categorical_cols}\")\n",
    "# get the encoder \n",
    "encoders = getEncoder(categorical_cols,df_train_x, df_train_x)\n",
    "#convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_train_x\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "df_train_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 85144 entries, 359175 to 164960\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   year          85144 non-null  Int64 \n",
      " 1   manufacturer  85144 non-null  int32 \n",
      " 2   model         85144 non-null  string\n",
      " 3   condition     50745 non-null  string\n",
      " 4   cylinders     51021 non-null  string\n",
      " 5   fuel          84604 non-null  string\n",
      " 6   odometer      85144 non-null  Int64 \n",
      " 7   transmission  84657 non-null  string\n",
      " 8   drive         59148 non-null  string\n",
      " 9   type          66751 non-null  string\n",
      " 10  paint_color   59269 non-null  string\n",
      " 11  vehicle_age   85144 non-null  Int64 \n",
      "dtypes: Int64(3), int32(1), string(8)\n",
      "memory usage: 8.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_test_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arg must be a list, tuple, 1-d array, or Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mto_numeric(df_train_x)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\numeric.py:191\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[0;32m    189\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([arg], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg must be a list, tuple, 1-d array, or Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     values \u001b[38;5;241m=\u001b[39m arg\n",
      "\u001b[1;31mTypeError\u001b[0m: arg must be a list, tuple, 1-d array, or Series"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 607\n",
      "[LightGBM] [Info] Number of data points in the train set: 340537, number of used features: 12\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.90 MB) transferred to GPU in 0.004652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 13900.000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: model: string, condition: string, cylinders: string, fuel: string, transmission: string, drive: string, type: string, paint_color: string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m modelCV\u001b[38;5;241m.\u001b[39mfit(df_train_x, df_train_y)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#predict\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m modelCV\u001b[38;5;241m.\u001b[39mpredict(df_test_x)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#evaluation\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# RMSE\u001b[39;00m\n\u001b[0;32m     23\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(df_test_y, y_pred))\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:519\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    518\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:961\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m _choose_param_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    959\u001b[0m predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_n_jobs(predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mpredict(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     X, raw_score\u001b[38;5;241m=\u001b[39mraw_score, start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration, num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m    963\u001b[0m     pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf, pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib, validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m    964\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params\n\u001b[0;32m    965\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:4453\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   4451\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4452\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   4454\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   4455\u001b[0m     start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   4456\u001b[0m     num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   4457\u001b[0m     raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   4458\u001b[0m     pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   4459\u001b[0m     pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   4460\u001b[0m     data_has_header\u001b[38;5;241m=\u001b[39mdata_has_header,\n\u001b[0;32m   4461\u001b[0m     validate_features\u001b[38;5;241m=\u001b[39mvalidate_features\n\u001b[0;32m   4462\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:1116\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     _safe_call(\n\u001b[0;32m   1108\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterValidateFeatureNames(\n\u001b[0;32m   1109\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         )\n\u001b[0;32m   1113\u001b[0m     )\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 1116\u001b[0m     data \u001b[38;5;241m=\u001b[39m _data_from_pandas(\n\u001b[0;32m   1117\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   1118\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1119\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m         pandas_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical\n\u001b[0;32m   1121\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1123\u001b[0m predict_type \u001b[38;5;241m=\u001b[39m _C_API_PREDICT_NORMAL\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_score:\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:825\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    821\u001b[0m df_dtypes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    822\u001b[0m target_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdf_dtypes)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 825\u001b[0m     _pandas_to_numpy(data, target_dtype\u001b[38;5;241m=\u001b[39mtarget_dtype),\n\u001b[0;32m    826\u001b[0m     feature_name,\n\u001b[0;32m    827\u001b[0m     categorical_feature,\n\u001b[0;32m    828\u001b[0m     pandas_categorical\n\u001b[0;32m    829\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:771\u001b[0m, in \u001b[0;36m_pandas_to_numpy\u001b[1;34m(data, target_dtype)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pandas_to_numpy\u001b[39m(\n\u001b[0;32m    768\u001b[0m     data: pd_DataFrame,\n\u001b[0;32m    769\u001b[0m     target_dtype: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.typing.DTypeLike\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    770\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m--> 771\u001b[0m     _check_for_bad_pandas_dtypes(data\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m         \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:763\u001b[0m, in \u001b[0;36m_check_for_bad_pandas_dtypes\u001b[1;34m(pandas_dtypes_series)\u001b[0m\n\u001b[0;32m    757\u001b[0m bad_pandas_dtypes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpandas_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column_name, pandas_dtype \u001b[38;5;129;01min\u001b[39;00m pandas_dtypes_series\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_allowed_numpy_dtype(pandas_dtype\u001b[38;5;241m.\u001b[39mtype)\n\u001b[0;32m    761\u001b[0m ]\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_pandas_dtypes:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas dtypes must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    764\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFields with bad pandas dtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(bad_pandas_dtypes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: model: string, condition: string, cylinders: string, fuel: string, transmission: string, drive: string, type: string, paint_color: string"
     ]
    }
   ],
   "source": [
    "# training\n",
    "numJobs=3\n",
    "cv=3\n",
    "paramgrid={\n",
    "                \"objective\": [\"mae\"],\n",
    "                \"n_estimators\": [750],\n",
    "                \"num_leaves\": [256],\n",
    "                \"subsample\": [1],\n",
    "                \"colsample_bytree\":[0.6],\n",
    "                \"learning_rate\": [0.001],\n",
    "            }\n",
    "\n",
    "model = lgb.LGBMRegressor(n_estimators= 500,random_state=4487,objective='mae',learning_rate=0.05,importance_type= \"gain\",device=\"gpu\")\n",
    "modelCV= GridSearchCV(model,param_grid=paramgrid,n_jobs=numJobs,verbose=True,cv=cv)\n",
    "modelCV.fit(df_train_x, df_train_y)\n",
    "\n",
    "#predict\n",
    "y_pred = modelCV.predict(df_test_x)\n",
    "\n",
    "#evaluation\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(df_test_y, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(df_test_y, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# R2\n",
    "r2 = r2_score(df_test_y, y_pred)\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "#Residual Analysis: \n",
    "residuals = df_test_y - y_pred\n",
    "\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
