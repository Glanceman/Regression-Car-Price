{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7991539,"sourceType":"datasetVersion","datasetId":4704710}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Regression Used Cars Dataset\n\nhttps://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data \n","metadata":{}},{"cell_type":"markdown","source":"#### **Dependency**","metadata":{}},{"cell_type":"code","source":"#! pip install lightgbm\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom itertools import combinations  # For creating combinations of elements\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\nimport lightgbm as lgb \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:15:17.705429Z","iopub.execute_input":"2024-04-06T17:15:17.706645Z","iopub.status.idle":"2024-04-06T17:15:19.880092Z","shell.execute_reply.started":"2024-04-06T17:15:17.706591Z","shell.execute_reply":"2024-04-06T17:15:19.878789Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from itertools import combinations  # For creating combinations of elements\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:15:23.344342Z","iopub.execute_input":"2024-04-06T17:15:23.345552Z","iopub.status.idle":"2024-04-06T17:15:23.391228Z","shell.execute_reply.started":"2024-04-06T17:15:23.345509Z","shell.execute_reply":"2024-04-06T17:15:23.389890Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"#### **Utility Function**","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=0):\n    \"\"\"\n    Iterate through all numeric columns of a dataframe and modify the data type\n    to reduce memory usage.\n    \"\"\"\n    # Calculate the initial memory usage of the DataFrame\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    # ðŸ”„ Iterate through each column in the DataFrame\n    for col in df.columns:\n        col_type = df[col].dtype\n        # Check if the column's data type is not 'object' (i.e., numeric)\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            # Check if the column's data type is an integer\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                # Check if the column's data type is a float\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float32)\n    # â„¹ï¸ Provide memory optimization information if 'verbose' is True\n    if verbose:\n        print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n        end_mem = df.memory_usage().sum() / 1024**2\n        print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n        decrease = 100 * (start_mem - end_mem) / start_mem\n        print(f\"Decreased by {decrease:.2f}%\")\n\n    # Return the DataFrame with optimized memory usage\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:15:27.451928Z","iopub.execute_input":"2024-04-06T17:15:27.452403Z","iopub.status.idle":"2024-04-06T17:15:27.470788Z","shell.execute_reply.started":"2024-04-06T17:15:27.452366Z","shell.execute_reply":"2024-04-06T17:15:27.469534Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### **Load Data**\n\nload csv inside data folder","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/vehicles/vehicles.csv\")\ndf=reduce_mem_usage(df,verbose=True)\ndf.shape\ndf[0:4]","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:15:32.178118Z","iopub.execute_input":"2024-04-06T17:15:32.178528Z","iopub.status.idle":"2024-04-06T17:16:15.862126Z","shell.execute_reply.started":"2024-04-06T17:15:32.178496Z","shell.execute_reply":"2024-04-06T17:16:15.856420Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Memory usage of dataframe is 84.68 MB\nMemory usage after optimization is: 76.54 MB\nDecreased by 9.62%\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"           id                                                url  \\\n0  7222695916  https://prescott.craigslist.org/cto/d/prescott...   \n1  7218891961  https://fayar.craigslist.org/ctd/d/bentonville...   \n2  7221797935  https://keys.craigslist.org/cto/d/summerland-k...   \n3  7222270760  https://worcester.craigslist.org/cto/d/west-br...   \n\n                   region                        region_url  price  year  \\\n0                prescott   https://prescott.craigslist.org   6000   NaN   \n1            fayetteville      https://fayar.craigslist.org  11900   NaN   \n2            florida keys       https://keys.craigslist.org  21000   NaN   \n3  worcester / central MA  https://worcester.craigslist.org   1500   NaN   \n\n  manufacturer model condition cylinders  ... size  type paint_color  \\\n0          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n1          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n2          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n3          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n\n  image_url description county state lat long posting_date  \n0       NaN         NaN    NaN    az NaN  NaN          NaN  \n1       NaN         NaN    NaN    ar NaN  NaN          NaN  \n2       NaN         NaN    NaN    fl NaN  NaN          NaN  \n3       NaN         NaN    NaN    ma NaN  NaN          NaN  \n\n[4 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>region</th>\n      <th>region_url</th>\n      <th>price</th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>model</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>...</th>\n      <th>size</th>\n      <th>type</th>\n      <th>paint_color</th>\n      <th>image_url</th>\n      <th>description</th>\n      <th>county</th>\n      <th>state</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>posting_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7222695916</td>\n      <td>https://prescott.craigslist.org/cto/d/prescott...</td>\n      <td>prescott</td>\n      <td>https://prescott.craigslist.org</td>\n      <td>6000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>az</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7218891961</td>\n      <td>https://fayar.craigslist.org/ctd/d/bentonville...</td>\n      <td>fayetteville</td>\n      <td>https://fayar.craigslist.org</td>\n      <td>11900</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ar</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7221797935</td>\n      <td>https://keys.craigslist.org/cto/d/summerland-k...</td>\n      <td>florida keys</td>\n      <td>https://keys.craigslist.org</td>\n      <td>21000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>fl</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7222270760</td>\n      <td>https://worcester.craigslist.org/cto/d/west-br...</td>\n      <td>worcester / central MA</td>\n      <td>https://worcester.craigslist.org</td>\n      <td>1500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ma</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows Ã— 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### **Split dataset** ","metadata":{}},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.2)\nprint(df_train.shape, df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:16:20.294405Z","iopub.execute_input":"2024-04-06T17:16:20.294886Z","iopub.status.idle":"2024-04-06T17:16:21.254742Z","shell.execute_reply.started":"2024-04-06T17:16:20.294838Z","shell.execute_reply":"2024-04-06T17:16:21.252814Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(341504, 26) (85376, 26)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Data Function**\n\ndata preperation\n\nfeature engineering","metadata":{}},{"cell_type":"code","source":"def data_preparation(df:pd.DataFrame)->pd.DataFrame:\n    \"\"\"\"\n    make data valid\n    \"\"\"\n    #There are too many categories for manufacturer and region,to reduce the risk of overfitting,we should cut the number of categories.\n    mf = df['manufacturer'].value_counts()\n    df['manufacturer'] = df['manufacturer'].apply(lambda s: s if str(s) in mf[:30] else 'others')\n\n    rg = df['region'].value_counts()\n    df['region'] = df['region'].apply(lambda s: s if str(s) in rg[:100] else 'others')\n  \n    #Create df1, get the average value of each year with deleting NAN and outliers, then assign it to the NAN in df, \n    #and then delete the outliers in df to get the latest data set\n    df1 = df.copy()\n    odometer_data = df1['odometer']\n    odometer_data_cleaned = odometer_data.dropna()\n    kmeans = KMeans(n_clusters=4)\n    kmeans.fit(odometer_data_cleaned.values.reshape(-1, 1))\n    outliers = odometer_data_cleaned[kmeans.labels_ == 1]\n    df1 = df1[~df1['odometer'].isin(outliers)]\n\n    mean_odometer = df1.groupby('year')['odometer'].mean()\n    mean_odometer_dict = mean_odometer.to_dict()\n\n    df['odometer'] = df.apply(lambda row: mean_odometer_dict[row['year']] if pd.isnull(row['odometer']) and row['year'] in mean_odometer_dict else row['odometer'], axis=1)\n\n    #The rest in odometer does not match the NAN of yaer,replaced using the mean\n    mean_avg_odometer = mean_odometer.mean()\n    df['odometer'] = df['odometer'].fillna(mean_avg_odometer)\n\n    odometer_data_new = df['odometer']\n    kmeans = KMeans(n_clusters=4)\n    kmeans.fit(odometer_data_new.values.reshape(-1, 1))\n    outliers = odometer_data_new[kmeans.labels_ == 1]\n    df = df[~df['odometer'].isin(outliers)]\n\n    #We just keep 10%(about $500)~99.9% of the 'price' value,kick off the ridiculious price.\n    df = df[(df['price']<df['price'].quantile(0.999)) & (df['price']>df['price'].quantile(0.1))]\n\n    #use linear regression to prediect values for null in year col.\n    features = [\"price\",'odometer']\n    df_complete = df.dropna(subset=[\"year\"] + features)\n    X_train = df_complete[features]\n    y_train = df_complete[\"year\"]\n    regression_model_year = LinearRegression()\n    regression_model_year.fit(X_train, y_train)\n    X_missing = df[df[\"year\"].isnull()][features]\n    if X_missing.shape[0] > 0:\n        predicted_year = regression_model_year.predict(X_missing)\n        df.loc[df[\"year\"].isnull(), \"year\"] = predicted_year.round().astype(int)\n   \n\n    #Fill null values using the modes of \"manufacturer\", \"cylinders\", 'fuel',\"title_status\", \"transmission\",\"drive\", \"type\", \"paint_color\", \"lat\", \"long\"\n    columns_to_fillna = ['manufacturer', 'cylinders', 'fuel', 'title_status', 'transmission',\n             'drive', 'type', 'paint_color', 'lat', 'long','posting_date']\n    modes = df[columns_to_fillna].mode().iloc[0]\n    df.loc[:, columns_to_fillna] = df.loc[:, columns_to_fillna].fillna(value=modes)\n\n    #for \"condition\" col: Fill NAN with randomly selected data from that column to manipulate the more possible results.\n    # Calculate the probability of each value (excluding NaN)\n    prob_values = df[df['condition'].notna()]['condition'].value_counts(normalize=True)\n    condition_options = df[\"condition\"].unique()\n    df.loc[df['condition'].isna(), 'condition'] = np.random.choice(prob_values.index, size=df['condition'].isna().sum(), p=prob_values.values)\n    df['condition'] = df['condition'].astype(str)\n\n    # Calculate the probability of each value (excluding 'other')\n    prob_values = df[df['cylinders'] != 'other']['cylinders'].value_counts(normalize=True)\n    # Assign 'other' values based on the probability\n    df.loc[df['cylinders'] == 'other', 'cylinders'] = np.random.choice(prob_values.index, size=df['cylinders'].eq('other').sum(), p=prob_values.values)\n    # Extract numeric values from the 'cylinder' column\n    df['cylinders'] = df['cylinders'].str.extract('(\\d+)').astype(int)\n\n\n    y = df['price']\n    x =df.drop(columns=['price'])\n\n    return x,y\n\ndef feature_engineering(df:pd.DataFrame)->pd.DataFrame:\n    \"\"\"\"\n    select useful feature\n    \"\"\"\n    #vehicle_age=posting_year - year, get the usage time of this vehicle\n    df[\"posting_date\"] = pd.to_datetime(df[\"posting_date\"], utc=True)\n    df[\"posting_year\"] = df[\"posting_date\"].dt.year\n    df[\"vehicle_age\"] = df[\"posting_year\"] - df[\"year\"]\n    \n    #Remove meaningless columns\n    #modify\n    df.drop(['id','url','region','region_url','model','title_status',\n         'image_url','VIN','size','county','description','state',\n         'lat','long','posting_date','posting_year'], \n        axis=1, inplace=True)\n    \n    return df\n\ndef encoding(df:pd.DataFrame,encoders=None)->pd.DataFrame:\n    cols = df.columns.values.tolist()\n    numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    categorical_cols = []\n    for col in cols:\n        if df[col].dtype in numerics: continue\n        categorical_cols.append(col)\n\n    if(encoders==None):\n        encoders=[]\n        for col in categorical_cols:\n            le = preprocessing.LabelEncoder()\n            le.fit(list(df[col].astype(str).values))\n            df[col] = le.transform(list(df[col].astype(str).values))\n            encoders.append(le)\n    else:\n        id=0\n        for col in categorical_cols:\n            le = encoders[id]\n            df[col] = le.transform(list(df[col].astype(str).values))\n            id=id+1\n\n    return df,encoders\n\n\n\ndef data_preprocessing(df:pd.DataFrame ,datasetType=\"train\", labelEncoders=None)->pd.DataFrame:\n    x , y =data_preparation(df)\n    x=feature_engineering(x)\n    encoders=labelEncoders\n    if(datasetType==\"train\"):\n        x,encoders=encoding(x,encoders=encoders)\n    if(datasetType==\"test\"):\n        if(encoders==None):\n            print(\"Please give a encoder\")\n            raise RuntimeError\n        x,_ = encoding(x,encoders)\n    return x,y,encoders","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:33:00.222461Z","iopub.execute_input":"2024-04-06T17:33:00.223368Z","iopub.status.idle":"2024-04-06T17:33:00.260566Z","shell.execute_reply.started":"2024-04-06T17:33:00.223325Z","shell.execute_reply":"2024-04-06T17:33:00.259123Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df_train_x,df_train_y,encoders = data_preprocessing(df_train,datasetType=\"train\")\ndf_test_x, df_test_y,_ = data_preprocessing(df_test,datasetType=\"test\",labelEncoders=encoders)\nprint(df_train_x.isna().sum())\nprint(df['type'].unique())\nprint(df_train_x.shape, df_train_y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:33:03.115862Z","iopub.execute_input":"2024-04-06T17:33:03.116295Z","iopub.status.idle":"2024-04-06T17:34:10.124810Z","shell.execute_reply.started":"2024-04-06T17:33:03.116262Z","shell.execute_reply":"2024-04-06T17:34:10.123362Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"year            0\nmanufacturer    0\ncondition       0\ncylinders       0\nfuel            0\nodometer        0\ntransmission    0\ndrive           0\ntype            0\npaint_color     0\nvehicle_age     0\ndtype: int64\n[nan 'pickup' 'truck' 'other' 'coupe' 'SUV' 'hatchback' 'mini-van' 'sedan'\n 'offroad' 'bus' 'van' 'convertible' 'wagon']\n(306661, 11) (306661,)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train_x[0:4]","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:22:13.349417Z","iopub.execute_input":"2024-04-06T17:22:13.350498Z","iopub.status.idle":"2024-04-06T17:22:13.369074Z","shell.execute_reply.started":"2024-04-06T17:22:13.350456Z","shell.execute_reply":"2024-04-06T17:22:13.367784Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"          year  manufacturer  condition  cylinders  fuel  odometer  \\\n253076  2018.0            22          2          6     0    3400.0   \n32180   2021.0            28          0          4     2       4.0   \n28067   2008.0            15          0          6     3   79488.0   \n51653   2008.0            18          0          6     2   89419.0   \n\n        transmission  drive  type  paint_color  vehicle_age  \n253076             0      0     9           10          3.0  \n32180              0      1     0           10          0.0  \n28067              0      0     7           10         13.0  \n51653              0      0     2           10         13.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>fuel</th>\n      <th>odometer</th>\n      <th>transmission</th>\n      <th>drive</th>\n      <th>type</th>\n      <th>paint_color</th>\n      <th>vehicle_age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>253076</th>\n      <td>2018.0</td>\n      <td>22</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3400.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>10</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>32180</th>\n      <td>2021.0</td>\n      <td>28</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28067</th>\n      <td>2008.0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>79488.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>10</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>51653</th>\n      <td>2008.0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>89419.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>10</td>\n      <td>13.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test_x[0:4]","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:22:16.509301Z","iopub.execute_input":"2024-04-06T17:22:16.509742Z","iopub.status.idle":"2024-04-06T17:22:16.529722Z","shell.execute_reply.started":"2024-04-06T17:22:16.509702Z","shell.execute_reply":"2024-04-06T17:22:16.528231Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"          year  manufacturer  condition  cylinders  fuel  odometer  \\\n45741   2011.0            11          0          8     2  124000.0   \n8891    2020.0             8          2          8     2     728.0   \n200555  2009.0             8          2          8     2  172500.0   \n255960  2002.0             8          2          8     0  185000.0   \n\n        transmission  drive  type  paint_color  vehicle_age  \n45741              0      0     7           10         10.0  \n8891               2      2     3            1          1.0  \n200555             0      0     8            1         12.0  \n255960             0      0     0            8         19.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>fuel</th>\n      <th>odometer</th>\n      <th>transmission</th>\n      <th>drive</th>\n      <th>type</th>\n      <th>paint_color</th>\n      <th>vehicle_age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45741</th>\n      <td>2011.0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>124000.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>8891</th>\n      <td>2020.0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>2</td>\n      <td>728.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>200555</th>\n      <td>2009.0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>2</td>\n      <td>172500.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>255960</th>\n      <td>2002.0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>185000.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>19.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### **Training and Evaluation**","metadata":{}},{"cell_type":"code","source":"# training\nnumJobs=3\ncv=5\nparamgrid={\n                \"objective\": [\"mae\"],\n                \"n_estimators\": [500,750],\n                \"num_leaves\": [256],\n                \"subsample\": [1],\n                \"colsample_bytree\":[0.6],\n                \"learning_rate\": [0.001],\n            }\n\nmodel = lgb.LGBMRegressor(n_estimators= 500,random_state=4487,objective='mae',learning_rate=0.05,importance_type= \"gain\",device=\"gpu\")\nmodelCV= GridSearchCV(model,param_grid=paramgrid,n_jobs=numJobs,verbose=True,cv=cv)\nmodelCV.fit(df_train_x, df_train_y)\n\n#predict\ny_pred = modelCV.predict(df_test_x)\n\n#evaluation\n\n# RMSE\nrmse = np.sqrt(mean_squared_error(df_test_y, y_pred))\nprint(f\"Root Mean Squared Error: {rmse}\")\n\n# MAE\nmae = mean_absolute_error(df_test_y, y_pred)\nprint(f\"Mean Absolute Error: {mae}\")\n\n# R2\nr2 = r2_score(df_test_y, y_pred)\nprint(f\"R-squared: {r2}\")\n\n#Residual Analysis: \nresiduals = df_test_y - y_pred\n\nplt.scatter(y_pred, residuals)\nplt.axhline(y=0, color='r', linestyle='--')\nplt.xlabel('Predicted Values')\nplt.ylabel('Residuals')\nplt.title('Residual Plot')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = make_column_transformer(\n    (OneHotEncoder(), [\"manufacturer\",'condition', 'cylinders', 'fuel', 'transmission', 'drive', 'type', 'paint_color' ]),\n    (StandardScaler(), [\"year\",\"odometer\",\"vehicle_age\"]),\n    remainder=\"passthrough\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:34:20.411262Z","iopub.execute_input":"2024-04-06T17:34:20.411815Z","iopub.status.idle":"2024-04-06T17:34:20.417618Z","shell.execute_reply.started":"2024-04-06T17:34:20.411768Z","shell.execute_reply":"2024-04-06T17:34:20.416637Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def random_search(_model,_preprocessor,_param_dist):\n    pipeline = make_pipeline(_preprocessor, _model)\n    random = RandomizedSearchCV(pipeline, param_distributions=_param_dist, n_iter=100, cv=5, n_jobs=16)\n    random.fit(df_train_x, df_train_y)\n    # Print the best hyperparameters and the corresponding score\n    print(\"Best parameters: {}\".format(random.best_params_))\n    print(\"Best cross-validation score: {:.2f}\".format(random.best_score_))\n    return random\n\n\ndef grid_search(_model,_preprocessor,_param_grid):\n    # Define the Gradient Boosting regression model\n    # Define the pipeline to preprocess the features and fit the model\n    pipeline = make_pipeline(_preprocessor, _model)\n    grid = GridSearchCV(pipeline, param_grid=_param_grid, cv=5, n_jobs=16)\n    grid.fit(df_train_x, df_train_y)\n    # Print the best hyperparameters and the corresponding score\n    print(\"Best parameters: {}\".format(grid.best_params_))\n    print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n    return grid\n    \ndef test_score(_model,_preprocessor):\n    best_pipeline = make_pipeline(_preprocessor, _model)\n    best_pipeline.fit(df_train_x, df_train_y)\n    df_test_pred = best_pipeline.predict(df_test_x)\n    rmse = np.sqrt(mean_squared_error(df_test_y, df_test_pred))\n    mae = mean_absolute_error(df_test_y, df_test_pred)\n    r2 = r2_score(df_test_y, df_test_pred)\n    print(\"R2 score: {}\".format(r2))\n    print(\"RMSE: {}\".format(rmse))\n    print(\"MAE: {}\".format(mae))\ndef test_score_param(_grid):\n    df_test_pred = _grid.best_estimator_.predict(df_test_x)\n    rmse = np.sqrt(mean_squared_error(df_test_y, df_test_pred))\n    mae = mean_absolute_error(df_test_y, df_test_pred)\n    r2 = r2_score(df_test_y, df_test_pred)\n    print(\"R2 score: {}\".format(r2))\n    print(\"RMSE: {}\".format(rmse))\n    print(\"MAE: {}\".format(mae))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:34:21.605915Z","iopub.execute_input":"2024-04-06T17:34:21.606767Z","iopub.status.idle":"2024-04-06T17:34:21.628530Z","shell.execute_reply.started":"2024-04-06T17:34:21.606726Z","shell.execute_reply":"2024-04-06T17:34:21.625859Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"param_dist = {\n        \"gradientboostingregressor__n_estimators\": sp_randint(50, 200),\n        \"gradientboostingregressor__max_depth\": sp_randint(5, 10),\n        \"gradientboostingregressor__learning_rate\": uniform(0.0, 1.0),\n        \"gradientboostingregressor__subsample\": uniform(0.0, 1.0),\n        \"gradientboostingregressor__loss\": ['squared_error', 'quantile', 'huber', 'absolute_error'],\n        \"gradientboostingregressor__min_samples_split\": sp_randint(2, 10),\n        \"gradientboostingregressor__min_samples_leaf\": sp_randint(1, 10),\n        \"gradientboostingregressor__max_features\": ['sqrt', 'log2', None],\n        \"gradientboostingregressor__min_impurity_decrease\": uniform(0.0, 0.1)\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:34:22.769244Z","iopub.execute_input":"2024-04-06T17:34:22.769674Z","iopub.status.idle":"2024-04-06T17:34:22.783983Z","shell.execute_reply.started":"2024-04-06T17:34:22.769641Z","shell.execute_reply":"2024-04-06T17:34:22.782731Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"param_grid = {\n        \"gradientboostingregressor__n_estimators\": [120,128,135,145],\n        \"gradientboostingregressor__max_depth\": [6, 7, 8],\n        \"gradientboostingregressor__learning_rate\": [0.55,0.6366443216222826,0.7,0.75],\n        \"gradientboostingregressor__subsample\": [0.3, 0.39654278232127016, 0.5],\n        \"gradientboostingregressor__loss\": ['huber'],\n        \"gradientboostingregressor__min_samples_split\": [1,2,3],\n        \"gradientboostingregressor__min_samples_leaf\": [3,4,5],\n        \"gradientboostingregressor__max_features\": ['sqrt', 'log2', None],\n        \"gradientboostingregressor__min_impurity_decrease\": [0.8,0.09041586944937485, 0.1]\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:34:23.831275Z","iopub.execute_input":"2024-04-06T17:34:23.831693Z","iopub.status.idle":"2024-04-06T17:34:23.839344Z","shell.execute_reply.started":"2024-04-06T17:34:23.831646Z","shell.execute_reply":"2024-04-06T17:34:23.837861Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"best_model = GradientBoostingRegressor(\n        n_estimators=100,\n        max_depth=7,\n        learning_rate=1,\n        subsample=0.8,\n        loss='huber',\n        random_state=42\n    )\nbest_model_2=GradientBoostingRegressor(\n        n_estimators=128,\n        max_depth=7,\n        learning_rate=0.6366443216222826,\n        subsample=0.39654278232127016,\n        loss='huber',\n        min_samples_leaf=4,\n        min_impurity_decrease=0.09041586944937485,\n        min_samples_split=2\n)\nparam_grid_G={}\ngrid_G=grid_search(GradientBoostingRegressor(),preprocessor,param_grid_G)\ntest_score_param(grid_G)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:43:44.516338Z","iopub.execute_input":"2024-04-06T17:43:44.517659Z","iopub.status.idle":"2024-04-06T17:51:36.713812Z","shell.execute_reply.started":"2024-04-06T17:43:44.517597Z","shell.execute_reply":"2024-04-06T17:51:36.712383Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Best parameters: {}\nBest cross-validation score: 0.69\nR2 score: 0.6912381222180283\nRMSE: 8150.397019531025\nMAE: 5130.150794148496\n","output_type":"stream"}]},{"cell_type":"code","source":"from xgboost import XGBRegressor\nparam_grid_X={}\ngrid_X=grid_search(XGBRegressor(),preprocessor,param_grid_X)\ntest_score_param(grid_X)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:34:28.063810Z","iopub.execute_input":"2024-04-06T17:34:28.064239Z","iopub.status.idle":"2024-04-06T17:35:00.163417Z","shell.execute_reply.started":"2024-04-06T17:34:28.064204Z","shell.execute_reply":"2024-04-06T17:35:00.162097Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Best parameters: {}\nBest cross-validation score: 0.78\nR2 score: 0.7811098333522429\nRMSE: 6862.463596839045\nMAE: 4166.622307841605\n","output_type":"stream"}]},{"cell_type":"code","source":"param_grid_L={}\ngrid_L=grid_search(LinearRegression(),preprocessor,param_grid_L)\ntest_score_param(grid_L)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:43:23.589546Z","iopub.execute_input":"2024-04-06T17:43:23.589931Z","iopub.status.idle":"2024-04-06T17:43:44.513025Z","shell.execute_reply.started":"2024-04-06T17:43:23.589893Z","shell.execute_reply":"2024-04-06T17:43:44.511328Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Best parameters: {}\nBest cross-validation score: 0.48\nR2 score: 0.4770517902454956\nRMSE: 10607.090346971849\nMAE: 6995.104582988402\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}